{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge facility information\n",
    "\n",
    "Merge facility data from HCRIS (Healthcare Cost Reporting Information System) and DH (Definitive Healthcare) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from os.path import join, isdir\n",
    "\n",
    "from covidcaremap.geo import spatial_join_facilities\n",
    "from covidcaremap.data import processed_data_path, external_data_path\n",
    "from covidcaremap.mapping import HospMap\n",
    "from covidcaremap.merge import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geocoded datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcris = gpd.read_file(processed_data_path('usa_facilities_hcris_geocoded.geojson'), encoding='utf-8')\n",
    "dh = gpd.read_file(processed_data_path('dh_geocoded_v1_0326202.geojson'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns to match between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcris.rename(columns={\n",
    "    'ST_ABBR': 'STATE_NAME',\n",
    "    'Zip_Code': 'ZIP_CODE'\n",
    "}, inplace=True)\n",
    "\n",
    "dh['STATE_NAME'] = dh['ST_ABBR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of states to iterate over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = hcris['STATE_NAME'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data set, data set name, and data set uid for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcris_info = (hcris, 'HCRIS', 'Provider Number')\n",
    "dh_info = (dh, 'DH', 'OBJECTID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_by_state(d1, d2, map_dir=None, str_match_method='name'):\n",
    "    d1, name1, uid1 = d1\n",
    "    d2, name2, uid2 = d2\n",
    "    \n",
    "    if not os.path.isdir(processed_data_path(map_dir)):\n",
    "        os.mkdir(processed_data_path(map_dir))\n",
    "    \n",
    "    state_matches = {}\n",
    "    for state in all_states:\n",
    "        print('Matching facilities in {}'.format(state))\n",
    "        if state not in state_matches.keys():\n",
    "            d1_s = d1[d1['STATE_NAME'] == state].reset_index().copy()\n",
    "            d2_s = d2[d2['STATE_NAME'] == state].reset_index().copy()\n",
    "            m = Matcher(d1_s, d2_s, uid1, uid2)\n",
    "            m.match_point_set((100, 500), 10, str_match_method=str_match_method)\n",
    "            if map_dir:\n",
    "                all_map = m.map_all((name1, name2), ['match source', 'dist_apart'])\n",
    "                all_map.add_layer_selector()\n",
    "                all_map.save(join(processed_data_path('{}'.format(map_dir)), '{}.html'.format(state)))\n",
    "            state_matches[state] = m\n",
    "    \n",
    "    ds = {\n",
    "        f'{name1}_matched': [],\n",
    "        f'{name2}_matched': [],\n",
    "        f'{name1}_unmatched': [],\n",
    "        f'{name2}_unmatched': [],\n",
    "        'matching_dfs': []\n",
    "    }\n",
    "    \n",
    "    for _, v in state_matches.items():\n",
    "        ds[f'{name1}_matched'].append(v.d1_matched)\n",
    "        ds[f'{name2}_matched'].append(v.d2_matched)\n",
    "        ds[f'{name1}_unmatched'].append(v.d1_unmatched)\n",
    "        ds[f'{name2}_unmatched'].append(v.d2_unmatched)\n",
    "        ds['matching_dfs'].append(v.matching_key_df())\n",
    "    \n",
    "    for k, v in ds.items():\n",
    "        ds[k] = pd.concat(v)\n",
    "        if isinstance(ds[k], gpd.GeoDataFrame):\n",
    "            ds[k] = ds[k].to_crs('epsg:4326')\n",
    "    \n",
    "    print('------------')\n",
    "    n_matched = len(ds['matching_dfs'])\n",
    "    n_unmatched = len(ds[f'{name1}_unmatched'])\n",
    "    n_total = n_matched + n_unmatched\n",
    "    pct_matched = round((n_matched / n_total) * 100, 1)\n",
    "    print(f'{name1} to {name2} matches: {pct_matched}% ({n_matched} of {n_total})')\n",
    "    \n",
    "    return state_matches, ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the two data sets state by state, writing off folium maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching facilities in AL\n",
      "Completed matching and deduping facilities, matched 109 of 136\n",
      "Matching facilities in AK\n",
      "Completed matching and deduping facilities, matched 23 of 26\n",
      "Matching facilities in AZ\n",
      "Completed matching and deduping facilities, matched 104 of 125\n",
      "Matching facilities in AR\n",
      "Completed matching and deduping facilities, matched 95 of 109\n",
      "Matching facilities in CA\n",
      "Completed [250] of 445 facilities, prelim matched 230\n",
      "Completed matching and deduping facilities, matched 401 of 445\n",
      "Matching facilities in CO\n",
      "Completed matching and deduping facilities, matched 101 of 110\n",
      "Matching facilities in CT\n",
      "Completed matching and deduping facilities, matched 40 of 43\n",
      "Matching facilities in DE\n",
      "Completed matching and deduping facilities, matched 14 of 16\n",
      "Matching facilities in DC\n",
      "Completed matching and deduping facilities, matched 11 of 13\n",
      "Matching facilities in FL\n",
      "Completed [250] of 273 facilities, prelim matched 236\n",
      "Completed matching and deduping facilities, matched 246 of 273\n",
      "Matching facilities in GA\n",
      "Completed matching and deduping facilities, matched 160 of 187\n",
      "Matching facilities in HI\n",
      "Completed matching and deduping facilities, matched 26 of 28\n",
      "Matching facilities in ID\n",
      "Completed matching and deduping facilities, matched 47 of 55\n",
      "Matching facilities in IL\n",
      "Completed matching and deduping facilities, matched 198 of 213\n",
      "Matching facilities in IN\n",
      "Completed matching and deduping facilities, matched 158 of 185\n",
      "Matching facilities in IA\n",
      "Completed matching and deduping facilities, matched 120 of 125\n",
      "Matching facilities in KS\n",
      "Completed matching and deduping facilities, matched 143 of 162\n",
      "Matching facilities in KY\n",
      "Completed matching and deduping facilities, matched 106 of 121\n",
      "Matching facilities in LA\n",
      "Completed matching and deduping facilities, matched 188 of 241\n",
      "Matching facilities in ME\n",
      "Completed matching and deduping facilities, matched 38 of 42\n",
      "Matching facilities in MD\n",
      "Completed matching and deduping facilities, matched 55 of 65\n",
      "Matching facilities in MA\n",
      "Completed matching and deduping facilities, matched 94 of 113\n",
      "Matching facilities in MI\n",
      "Completed matching and deduping facilities, matched 151 of 177\n",
      "Matching facilities in MN\n",
      "Completed matching and deduping facilities, matched 135 of 148\n",
      "Matching facilities in MS\n",
      "Completed matching and deduping facilities, matched 103 of 121\n",
      "Matching facilities in MO\n",
      "Completed matching and deduping facilities, matched 129 of 161\n",
      "Matching facilities in MT\n",
      "Completed matching and deduping facilities, matched 65 of 65\n",
      "Matching facilities in NE\n",
      "Completed matching and deduping facilities, matched 94 of 102\n",
      "Matching facilities in NV\n",
      "Completed matching and deduping facilities, matched 56 of 61\n",
      "Matching facilities in NH\n",
      "Completed matching and deduping facilities, matched 30 of 30\n",
      "Matching facilities in NJ\n",
      "Completed matching and deduping facilities, matched 89 of 99\n",
      "Matching facilities in NM\n",
      "Completed matching and deduping facilities, matched 52 of 57\n",
      "Matching facilities in NY\n",
      "Completed matching and deduping facilities, matched 197 of 230\n",
      "Matching facilities in NC\n",
      "Completed matching and deduping facilities, matched 125 of 146\n",
      "Matching facilities in ND\n",
      "Completed matching and deduping facilities, matched 49 of 49\n",
      "Matching facilities in OH\n",
      "Completed [250] of 257 facilities, prelim matched 222\n",
      "Completed matching and deduping facilities, matched 215 of 257\n",
      "Matching facilities in OK\n",
      "Completed matching and deduping facilities, matched 140 of 166\n",
      "Matching facilities in OR\n",
      "Completed matching and deduping facilities, matched 61 of 64\n",
      "Matching facilities in PA\n",
      "Completed matching and deduping facilities, matched 211 of 248\n",
      "Matching facilities in PR\n",
      "Completed matching and deduping facilities, matched 28 of 65\n",
      "Matching facilities in RI\n",
      "Completed matching and deduping facilities, matched 13 of 15\n",
      "Matching facilities in SC\n",
      "Completed matching and deduping facilities, matched 77 of 90\n",
      "Matching facilities in SD\n",
      "Completed matching and deduping facilities, matched 57 of 64\n",
      "Matching facilities in TN\n",
      "Completed matching and deduping facilities, matched 135 of 166\n",
      "Matching facilities in TX\n",
      "Completed [250] of 687 facilities, prelim matched 220\n",
      "Completed [500] of 687 facilities, prelim matched 441\n",
      "Completed matching and deduping facilities, matched 531 of 687\n",
      "Matching facilities in UT\n",
      "Completed matching and deduping facilities, matched 58 of 63\n",
      "Matching facilities in VT\n",
      "Completed matching and deduping facilities, matched 16 of 16\n",
      "Matching facilities in VI\n",
      "Completed matching and deduping facilities, matched 1 of 2\n",
      "Matching facilities in VA\n",
      "Completed matching and deduping facilities, matched 101 of 123\n",
      "Matching facilities in WA\n",
      "Completed matching and deduping facilities, matched 99 of 107\n",
      "Matching facilities in WV\n",
      "Completed matching and deduping facilities, matched 57 of 66\n",
      "Matching facilities in WI\n",
      "Completed matching and deduping facilities, matched 141 of 149\n",
      "Matching facilities in WY\n",
      "Completed matching and deduping facilities, matched 30 of 32\n",
      "Matching facilities in GU\n",
      "Completed matching and deduping facilities, matched 2 of 2\n",
      "Matching facilities in MP\n",
      "Completed matching and deduping facilities, matched 1 of 1\n",
      "------------\n",
      "HCRIS to DH matches: 86.0% (5726 of 6662)\n"
     ]
    }
   ],
   "source": [
    "hcris_to_dh_matches, hcris_to_dh_data = match_by_state(\n",
    "    hcris_info, \n",
    "    dh_info, \n",
    "    'state_validation_maps_03-31-21_hcris-to-dh')\n",
    "\n",
    "HtoD_matches = hcris_to_dh_data['matching_dfs'].astype(str)\n",
    "HtoD_matches.to_csv(processed_data_path('HCRIS_to_DH_matching_key.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine into one dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some field names changed in the process of geocoding so we need to import the original datasets and join them using the newly created matching key to ensure that column names are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcris_original = gpd.read_file(processed_data_path('usa_hospital_beds_hcris2018.geojson'), encoding='utf-8')\n",
    "hcris_original['Provider Number'] = hcris_original['Provider Number'].astype(str)\n",
    "dh_original = gpd.read_file(external_data_path('dh_facility_data.geojson'), encoding='utf-8')\n",
    "dh_original['OBJECTID'] = dh_original['OBJECTID'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the `Provider Number` (HCRIS unique ID field) to the DH dataset by joining the key to it on `OBJECTID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_with_pn = pd.merge(dh_original, HtoD_matches[['OBJECTID', 'Provider Number']], how='left', on='OBJECTID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then join the HCRIS dataset to the updated DH dataset on `Provider Number`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(dh_with_pn, hcris_original.drop(columns='geometry'), how='left', on='Provider Number', suffixes=('', '_HCRIS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the necessary columns by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['OBJECTID', 'Provider Number', 'HOSPITAL_N', 'HOSPITAL_T', 'HQ_ADDRESS',\n",
    "        'HQ_ADDRE_1', 'HQ_CITY', 'HQ_STATE', 'HQ_ZIP_COD', 'COUNTY_NAM',\n",
    "        'STATE_NAME', 'STATE_FIPS', 'CNTY_FIPS', 'FIPS', 'NUM_LICENS',\n",
    "        'NUM_STAFFE', 'NUM_ICU_BE', 'BED_UTILIZ', 'Potential_', 'FYB', 'FYE',\n",
    "        'STATUS', 'CTRL_TYPE', 'HOSP10_Name', 'Street_Addr', 'PO_Box', 'City',\n",
    "        'State', 'Zip_Code', 'County', 'Hospital Adult and Peds Staffed Beds',\n",
    "        'Hospital Adult and Peds Bed Days Available',\n",
    "        'Hospital Adult and Peds Inpatient Days',\n",
    "        'Intensive Care Unit Staffed Beds',\n",
    "        'Intensive Care Unit Bed Days Available',\n",
    "        'Intensive Care Unit Inpatient Days', 'Coronary Care Unit Staffed Beds',\n",
    "        'Coronary Care Unit Bed Days Available',\n",
    "        'Coronary Care Unit Inpatient Days', 'Burn ICU Staffed Beds',\n",
    "        'Burn ICU Bed Days Available', 'Burn ICU Inpatient Days',\n",
    "        'Surgical ICU Staffed Beds', 'Surgical ICU Bed Days Available',\n",
    "        'Surgical ICU Inpatient Days', 'Total Staffed Beds',\n",
    "        'Total Bed Days Available', 'Total Inpatient Days',\n",
    "        'ICU Total Staffed Beds', 'ICU Total Bed Days Available',\n",
    "        'ICU Total Inpatient Days', 'ICU Occupancy Rate',\n",
    "        'Total Bed Occupancy Rate', 'geometry']\n",
    "\n",
    "full_df = full_df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write off the merged geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_file(processed_data_path('dh_hcris_merged_facility_data.geojson'), \n",
    "                encoding='utf-8', \n",
    "                driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
