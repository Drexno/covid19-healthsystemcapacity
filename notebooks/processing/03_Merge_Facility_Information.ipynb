{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge facility information\n",
    "\n",
    "Merge facility data from HCRIS (Healthcare Cost Reporting Information System) and DH (Definitive Healthcare) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from os.path import join, isdir\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from covidcaremap.data import (processed_data_path, \n",
    "                               external_data_path,\n",
    "                               local_data_path)\n",
    "from covidcaremap.merge import match_facilities, FacilityColumns\n",
    "from covidcaremap.mapping import map_facility_match_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs matches between different hospital facility datasets.\n",
    "\n",
    "See logic in `covidcaremap.merge.match_facilities` for information about how the matching is performed.\n",
    "\n",
    "Generally, the algorithm is as follows:\n",
    "\n",
    "- Compute the KNN (n=10) between all facilities.\n",
    "- Create a graph for containing every facility in HIFLD and an edge for each of its neighbors if the distance between the two is less than `MAX_DISTANCE`. \n",
    "- Get the [connected components](https://en.wikipedia.org/wiki/Component_(graph_theory)) of that graph as a set of potentially matched facilities and pass it to a method that:\n",
    "  - Determines the feasability of a match between each HIFLD facility and any DH and HCRIS facilities in the set, based on the numeric address number matching between the two or a name match. If it's deemed feasible (see `coidccaremap.merge.reduce_matched_facility_records` for exact logic), create a score between the facilities based on a [rapidfuzz](https://github.com/rhasspy/rapidfuzz) fuzz ratio for the name and address of the facilities.\n",
    "  - Generate the final match set per HIFLD facility by ordering the potential matches between HIFLD and DH or HCRIS facilities, choosing the first of each of DH and HCRIS, and ensuring there's no duplicate matches.\n",
    "- The matched sets over all components represents the matched facilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These keys to refer to the facility datasets by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIFLD = 'hifld'\n",
    "DH = 'dh'\n",
    "HCRIS = 'hcris'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MAX_DISTANCE` determines the maximum distance two facilities can be apart from each other and still considered as a potential match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DISTANCE = 500 # meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AUTHORITATIVE_DATASET` is the dataset that all the other facility datasets match against. All facilities in this dataset will be included in the final output; any unmatched facilities in the other datasets will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHORITATIVE_DATASET = HIFLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the facility datasets and make any necessary data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcris = gpd.read_file(processed_data_path('usa_hospital_beds_hcris2018.geojson'), encoding='utf-8')\n",
    "dh = gpd.read_file(processed_data_path('dh_geocoded_v1_0326202.geojson'), encoding='utf-8')\n",
    "hifld = gpd.read_file(processed_data_path('hifld_facility_data.geojson'), encoding='utf-8')\n",
    "\n",
    "# Drop OBJECTID as that is the ID column name \n",
    "hifld = hifld.drop(columns=['OBJECTID'])\n",
    "\n",
    "# Use a combined address field for DH as it's street address is split between two fields.\n",
    "dh['addr2'] = dh['HQ_ADDRE_1'].fillna('')\n",
    "dh['combined_address'] = dh['Street_Addr'] + ' ' + dh['addr2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration for the matching algorithm. It describes the dataframes and the column names of each facility dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_datasets = {\n",
    "    HIFLD: {\n",
    "        'df': hifld,\n",
    "        'columns': FacilityColumns(facility_id='ID',\n",
    "                                   facility_name='NAME',\n",
    "                                   street_address='ADDRESS')\n",
    "    },\n",
    "    DH: {\n",
    "        'df': dh,\n",
    "        'columns': FacilityColumns(facility_id='OBJECTID',\n",
    "                                   facility_name='HOSP10_Name',\n",
    "                                   street_address='combined_address')\n",
    "    },\n",
    "    HCRIS: {\n",
    "        'df': hcris,\n",
    "        'columns': FacilityColumns(facility_id='Provider Number',\n",
    "                                   facility_name='HOSP10_Name',\n",
    "                                   street_address='Street_Addr')\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the matching. This can take a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_result = match_facilities(facility_datasets, \n",
    "                                authoritative_dataset='hifld',\n",
    "                                max_distance=MAX_DISTANCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save off a map of the match results for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dir = local_data_path('merge_facility_validation_maps')\n",
    "if not os.path.isdir(map_dir):\n",
    "    os.makedirs(map_dir)\n",
    "all_map = map_facility_match_result(match_result, facility_datasets, 'hifld')\n",
    "all_map.add_layer_selector()\n",
    "all_map.save(os.path.join(map_dir, \n",
    "                          '{}.html'.format('-'.join([HIFLD, DH, HCRIS]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the merged facility information to GeoJSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_result.merged_df.to_file(processed_data_path('hifld-dh-hcris-merged.geojson'), \n",
    "                               encoding='utf-8', \n",
    "                               driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a JSON object describing all unmatched facilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(processed_data_path('unmatched-facilities_per_dataset.json'), 'w') as f:\n",
    "    f.write(json.dumps(match_result.get_unmatched_dict(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
