{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "from jenkspy import jenks_breaks\n",
    "from unidecode import unidecode\n",
    "\n",
    "from covidcaremap.data import external_data_path, processed_data_path\n",
    "from covidcaremap.ihme import IHME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration that will be used in the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_config = {\n",
    "    'dates': None, # Calculated below\n",
    "    'ihme_version': None, # Calculated below\n",
    "    'aggregations': {\n",
    "        'country': {\n",
    "            'per_capita_base': 1000000,\n",
    "            'breaks': { 'totals': None, 'per_capita': None } # Calculated below\n",
    "        },\n",
    "        'region': {\n",
    "            'per_capita_base': 100000,\n",
    "            'breaks': { 'totals': None, 'per_capita': None } # Calculated below\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in a range of country/region boundaries to match up to IHME location names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_gdf = gpd.read_file(external_data_path('us_states.geojson'), encoding='utf-8')\n",
    "countries_gdf = gpd.read_file(external_data_path('admin0.geojson'))\n",
    "spain_gdf = gpd.read_file('https://raw.githubusercontent.com/deldersveld/'\n",
    "                          'topojson/master/countries/spain/spain-comunidad.json')\n",
    "canary_islands_gdf = gpd.read_file('https://raw.githubusercontent.com/deldersveld/'\n",
    "                                   'topojson/master/countries/spain/canary-islands-province.json')\n",
    "italy_gdf = gpd.read_file('https://raw.githubusercontent.com/openpolis/'\n",
    "                          'geojson-italy/master/geojson/limits_IT_regions.geojson')\n",
    "admin1_gdf = gpd.read_file(external_data_path('admin1.geojson'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pop_gdf = gpd.read_file(processed_data_path('us_states_with_pop.geojson'))\n",
    "worldpop_country_df = pd.read_csv(external_data_path('worldpop-country-pop-for-ihme-2020.csv'))\n",
    "worldpop_region_df = pd.read_csv(external_data_path('worldpop-region-pop-for-ihme-2020.csv'))\n",
    "worldpop_admin1_df = pd.read_csv(external_data_path('worldpop-admin1-2020.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Admin0 and Admin1 worldpop data to support new countries and regions added by IHME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldpop_admin1_processed_df = worldpop_admin1_df[['adm1_code', 'population']] \\\n",
    "    .merge(admin1_gdf[['adm1_code', 'name']] , on='adm1_code') \\\n",
    "    .drop(columns=['adm1_code']) \\\n",
    "    .rename(columns={'name': 'location_name'})\n",
    "\n",
    "worldpop_admin0_processed_df = worldpop_admin1_df.groupby('adm0_a3')['population'].sum() \\\n",
    "    .to_frame() \\\n",
    "    .merge(countries_gdf[['ADM0_A3', 'NAME']] , left_on='adm0_a3', right_on='ADM0_A3') \\\n",
    "    .drop(columns=['ADM0_A3']) \\\n",
    "    .rename(columns={'NAME': 'location_name'})\n",
    "\n",
    "country_level_pops = set(worldpop_country_df['location_name'])\n",
    "worldpop_admin0_processed_df = worldpop_admin0_processed_df[\n",
    "    ~worldpop_admin0_processed_df['location_name'].isin(country_level_pops)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the latest IHME projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_df, ihme_version = IHME.get_latest(include_version=True)\n",
    "ihme_config['ihme_version'] = ihme_version\n",
    "print('\\n\\nMODEL VERSION: {}\\n\\n'.format(ihme_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns between IHME and the geospatial datasets so that they can be matched up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renames for better matching\n",
    "italy_gdf = italy_gdf.replace({\n",
    "    '''Valle d'Aosta/Vallée d'Aoste''': '''Valle d'Aosta'''\n",
    "})\n",
    "\n",
    "# Rename regions to line up with GeoJSON values.\n",
    "ihme_df = ihme_df.replace({\n",
    "    # Spain regions\n",
    "    'Andalucia': 'Andalucía',\n",
    "    'Aragon': 'Aragón',\n",
    "    'Castile and Leon': 'Castilla y León',\n",
    "    'Castile and León': 'Castilla y León',\n",
    "    'Catalonia': 'Cataluña',  \n",
    "    'Basque Country': 'País Vasco',\n",
    "    'Canary Islands': 'Islas Canarias',\n",
    "    'Valencian Community': 'Comunidad Valenciana',\n",
    "    \n",
    "    # Italy\n",
    "    'Provincia autonoma di Bolzano': 'Bozen',\n",
    "    'Provincia autonoma di Trento': 'Trento',\n",
    "    \n",
    "    # Germany\n",
    "    'Baden-Wurttemberg': 'Baden-Württemberg',\n",
    "    \n",
    "    # Canada\n",
    "    'Quebec': 'Québec', \n",
    "    \n",
    "    # Mexico\n",
    "    'State of Mexico': 'México',\n",
    "    'Mexico_two': 'México', # This changed in model version 2020_06_08\n",
    "    'Veracruz de Ignacio de la Llave': 'Veracruz',\n",
    "    'Michoacan de Ocampo': 'Michoacán',\n",
    "    'Michoacán de Ocampo': 'Michoacán',\n",
    "    \n",
    "    # Brazil\n",
    "    'Ceara': 'Ceará',\n",
    "    'Maranhao': 'Maranhão',\n",
    "    'Sao Paulo': 'São Paulo',\n",
    "    'Goias': 'Goiás',\n",
    "    'Amapa': 'Amapá',\n",
    "    'Paraiba': 'Paraíba',\n",
    "    'Espirito Santo': 'Espírito Santo',\n",
    "    \n",
    "    \n",
    "    # Countries\n",
    "    'Republic of Korea': 'South Korea',\n",
    "    'Republic of Moldova': 'Moldova',\n",
    "    'Parana': 'Paraná',\n",
    "    'Mexico_country': 'Mexico',\n",
    "    'Bolivia (Plurinational State of)': 'Bolivia',\n",
    "    'Russian Federation': 'Russia',\n",
    "    'Serbia': 'Republic of Serbia'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure we'll capture all the regions we want to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_regions = (\n",
    "    set(state_gdf['NAME'].values) |\n",
    "    set(countries_gdf['ADMIN'].values) |\n",
    "    set(admin1_gdf['name_en'].values) |\n",
    "    set(admin1_gdf['name'].values) |\n",
    "    set(spain_gdf['NAME_1'].values) |\n",
    "    set(canary_islands_gdf['NAME_1'].values) |\n",
    "    set(italy_gdf['reg_name'].values)\n",
    ")\n",
    "\n",
    "# We check against 'unidecoded' strings as well\n",
    "# as IHME does not use accented characters.\n",
    "missing_regions = (\n",
    "    set(ihme_df['location_name'].values) - \n",
    "    available_regions -\n",
    "    set(map(lambda x: x if x is None else unidecode(x), available_regions))\n",
    ")\n",
    "\n",
    "regions_to_ignore = set([\n",
    "   'Other Counties, WA', \n",
    "   'Life Care Center, Kirkland, WA',\n",
    "   'King and Snohomish Counties (excluding Life Care Center), WA'\n",
    "])\n",
    "if len(missing_regions - regions_to_ignore) != 0:\n",
    "    raise Exception(\"Missing regions: {}\".format(', '.join(missing_regions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Account for some location_names that could tie to multiple geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_geom(feature):\n",
    "    # La Rioja is a region in Argentina and Spain; we want Spain\n",
    "    if feature.get('name') == 'La Rioja' and feature['iso_a2'] != 'ES':\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of location name to geometries and population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dfs = [\n",
    "    (countries_gdf, 'ADMIN'),\n",
    "]\n",
    "\n",
    "country_pop_dfs = [\n",
    "    (worldpop_country_df, 'location_name', 'population'),\n",
    "    (worldpop_admin0_processed_df, 'location_name', 'population')\n",
    "]\n",
    "\n",
    "region_dfs = [\n",
    "    (state_gdf, 'NAME'),\n",
    "    (admin1_gdf, ['name', 'name_en']),\n",
    "    (spain_gdf, 'NAME_1'),\n",
    "    (canary_islands_gdf, 'NAME_1'),\n",
    "    (italy_gdf, 'reg_name')\n",
    "]\n",
    "\n",
    "region_pop_dfs = [\n",
    "    (state_pop_gdf, 'State Name', 'Population'),\n",
    "    (worldpop_region_df, 'location_name', 'population'),\n",
    "    (worldpop_admin1_processed_df, 'location_name', 'population')\n",
    "]\n",
    "\n",
    "state_names = set(state_gdf['NAME'].values)\n",
    "\n",
    "def get_geoms_by_name(dfs):\n",
    "    result = {}\n",
    "    seen = set([])\n",
    "    duplicates = set([])\n",
    "    \n",
    "    for df, name_cols in dfs:\n",
    "        if type(name_cols) is str:\n",
    "            name_cols = [name_cols]        \n",
    "        for _, feature in df.iterrows():\n",
    "            if avoid_geom(feature):\n",
    "                continue\n",
    "            row_names = set([])\n",
    "            for name_col in name_cols:\n",
    "                name = feature[name_col]\n",
    "                if name is not None:\n",
    "                    if name in row_names:\n",
    "                        continue\n",
    "                    row_names.add(name)\n",
    "                    if name in seen:\n",
    "                        duplicates.add(name)                       \n",
    "                    else:\n",
    "                        seen.add(name)\n",
    "                        result[name] = feature['geometry']\n",
    "                        decoded = unidecode(name)\n",
    "                        if decoded != name:\n",
    "                            if decoded not in result:                    \n",
    "                                result[decoded] = feature['geometry']\n",
    "    return result, duplicates\n",
    "\n",
    "def get_pop_by_name(dfs):\n",
    "    result = {}\n",
    "    duplicates = set([])\n",
    "    seen = set([])\n",
    "    \n",
    "    for df, name_col, pop_col in dfs:\n",
    "        seen_in_this_df = set([])\n",
    "        print(name_col)\n",
    "        for _, row in df.iterrows():            \n",
    "            name = row[name_col]\n",
    "            if name == 'Florida':\n",
    "                print('FLORIDA: {}'.format(row[pop_col]))\n",
    "            if name is not None:\n",
    "                if name in seen:\n",
    "                    duplicates.add(name)\n",
    "                    # If it's not a US state, delete it out to ensure manual handling.\n",
    "                    if name in seen_in_this_df:\n",
    "                        print('POP DUPLICATE NAME: {}, HANDLE MANUALLY IF NECESSARY'.format(name))                        \n",
    "                        if name in result:\n",
    "                            del result[name]\n",
    "                else:\n",
    "                    seen.add(name)\n",
    "                    seen_in_this_df.add(name)\n",
    "                    result[name] = row[pop_col]\n",
    "                    decoded = unidecode(name)\n",
    "                    if decoded != name:\n",
    "                        if decoded not in result:                    \n",
    "                            result[decoded] = row[pop_col]\n",
    "                        else:\n",
    "                            print('POP UNIDECODE DUPLICATE: {}'.format(decoded))\n",
    "    return result, duplicates\n",
    "\n",
    "print('==Processing country geoms....')\n",
    "country_geom_by_name, _ = get_geoms_by_name(country_dfs)\n",
    "print('==Processing country populations....')\n",
    "country_pop_by_name, country_pop_duplicates = get_pop_by_name(country_pop_dfs)\n",
    "print('==Processing region geoms....')\n",
    "region_geom_by_name, _ = get_geoms_by_name(region_dfs)  \n",
    "print('==Processing region populations....')\n",
    "region_pop_by_name, region_pop_duplicates = get_pop_by_name(region_pop_dfs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually input some population data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dominican Republic\n",
    "\n",
    "[\"Estimaciones y proyecciones de la población total\" (xlsx)](https://www.one.gob.do/categoria/tablagrafico?Gid=23). Oficina Nacional de Estadística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_pop_by_name['Dominican Republic'] = 10735896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mexico City\n",
    "\n",
    "[\"Mexico Demographics Profile 2018\"](https://www.indexmundi.com/mexico/demographics_profile.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_pop_by_name['Mexico City'] = 21672000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Republic of Serbia\n",
    "\n",
    "2019 Estimate\n",
    "\n",
    "[\"PBC Stats\"](http://www.stat.gov.rs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_pop_by_name['Republic of Serbia'] = 6963764"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handle duplicate entries in world pop\n",
    "\n",
    "The admin1 worldpop data has duplicate `loction_name` entries. Handle those cases here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spain, not Argentina\n",
    "region_pop_by_name['La Rioja'] = 315675 # (2018) Sources include:Instituto Nacional de Estadística, Eurostat\n",
    "\n",
    "# Brazil, not Cape Verde\n",
    "region_pop_by_name['Santa Catarina'] = 6727000 # (2014) Instituto Brasileiro de Geografia e Estatística\n",
    "\n",
    "# Brazil, not Columbia, Peru, or Venezuela\n",
    "region_pop_by_name['Amazonas'] = 4144597 # (2019 estimate)  Population estimates for the Brazilian municipalities and Federation Units on July 1, 2018\n",
    "\n",
    "# Brazil, not Mexico\n",
    "region_pop_by_name['Distrito Federal'] = 3015268 # (2019 estimate)  IBGE - Projeção da população"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure we're not missing geoms or population for any regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_with_geom = set(country_geom_by_name.keys()).union(set(region_geom_by_name))\n",
    "names_with_pop = set(country_pop_by_name.keys()).union(set(region_pop_by_name))\n",
    "\n",
    "geom_not_found = set([])\n",
    "pop_not_found = set([])\n",
    "for _, row in ihme_df.iterrows():\n",
    "    name = row['location_name']\n",
    "    if name not in names_with_geom:\n",
    "        geom_not_found.add(name)\n",
    "    if name not in names_with_pop:\n",
    "        pop_not_found.add(name)\n",
    "        \n",
    "if len(geom_not_found) > 0 or len(pop_not_found) > 0:\n",
    "    raise Exception(\"\"\"  \n",
    "        Geoms not found: {}\n",
    "        \n",
    "        Population not found: {}\n",
    "    \"\"\".format('\\n'.join(geom_not_found), '\\n'.join(pop_not_found))\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define methods for retrieving the geometry and population for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search region first then country to account for names like Georgia.\n",
    "# Account for other edge cases, like Mexico\n",
    "\n",
    "def get_geom(location_name):\n",
    "    if location_name == 'Mexico':\n",
    "        return country_geom_by_name.get(location_name)\n",
    "    \n",
    "    result = region_geom_by_name.get(\n",
    "        location_name,\n",
    "        country_geom_by_name.get(location_name)\n",
    "    )\n",
    "    if result is None:\n",
    "        raise Exception(\"IHME location_name {} geometry not found\".format(location_name))\n",
    "    return result\n",
    "\n",
    "def get_pop(location_name):\n",
    "    if location_name == 'Mexico':\n",
    "        return country_pop_by_name.get(location_name)\n",
    "    \n",
    "    result = region_pop_by_name.get(\n",
    "        location_name,\n",
    "        country_pop_by_name.get(location_name)\n",
    "    )\n",
    "    if result is None:\n",
    "        raise Exception(\"IHME location_name {} population not found\".format(location_name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename smoothed columns to better fit with the `_` deliniator used by the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_df = ihme_df.rename(columns={\n",
    "    'deaths_mean_smoothed': 'smoothed-deaths_mean',\n",
    "    'deaths_lower_smoothed': 'smoothed-deaths_lower',\n",
    "    'deaths_upper_smoothed': 'smoothed-deaths_upper',\n",
    "    'totdea_mean_smoothed': 'smoothed-totdea_mean',\n",
    "    'totdea_lower_smoothed': 'smoothed-totdea_lower',\n",
    "    'totdea_upper_smoothed': 'smoothed-totdea_upper',\n",
    "    'est_infections_mean': 'est-infections_mean',\n",
    "    'est_infections_lower': 'est-infections_lower',\n",
    "    'est_infections_upper': 'est-infections_upper',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define methods that generate the IHME GeoJSON for each of our region groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_cols = [\n",
    "    'allbed_mean', \n",
    "    'allbed_lower',\n",
    "    'allbed_upper', \n",
    "    'ICUbed_mean', \n",
    "    'ICUbed_lower', \n",
    "    'ICUbed_upper',\n",
    "    'InvVen_mean', \n",
    "    'InvVen_lower', \n",
    "    'InvVen_upper', \n",
    "    'deaths_mean',\n",
    "    'deaths_lower', \n",
    "    'deaths_upper',\n",
    "    'smoothed-deaths_mean',\n",
    "    'smoothed-deaths_lower', \n",
    "    'smoothed-deaths_upper',\n",
    "    'admis_mean', \n",
    "    'admis_lower',\n",
    "    'admis_upper', \n",
    "    'newICU_mean', \n",
    "    'newICU_lower', \n",
    "    'newICU_upper',\n",
    "    'totdea_mean', \n",
    "    'totdea_lower', \n",
    "    'totdea_upper', \n",
    "    'smoothed-totdea_mean', \n",
    "    'smoothed-totdea_lower', \n",
    "    'smoothed-totdea_upper', \n",
    "    'bedover_mean',\n",
    "    'bedover_lower', \n",
    "    'bedover_upper', \n",
    "    'icuover_mean', \n",
    "    'icuover_lower',\n",
    "    'icuover_upper',\n",
    "    'est-infections_mean',\n",
    "    'est-infections_lower',\n",
    "    'est-infections_upper'\n",
    "]\n",
    "\n",
    "metrics = set(map(lambda x: x.split('_')[0], value_cols))\n",
    "levels = set(map(lambda x: x.split('_')[1], value_cols))\n",
    "\n",
    "def gather_data_for_locations(df):\n",
    "    \"\"\"\n",
    "    Gathers data and the feature collection for the location_names\n",
    "    contained as keys inn geoms_by_name (which must be a subset to the keys\n",
    "    of pop_by_name)\n",
    "    \n",
    "    Returns the feature collection, the data, and the dates\n",
    "    \"\"\"\n",
    "    next_location_id = 0\n",
    "    name_to_id = {}\n",
    "    data = {}\n",
    "    dates = set([])\n",
    "    props_by_name = defaultdict(dict)\n",
    "    features = []\n",
    "    \n",
    "    def setup_location(name, location_id):\n",
    "        geom = get_geom(name)\n",
    "        pop = get_pop(name)\n",
    "        features.append({\n",
    "            'id': location_id,\n",
    "            'type': 'Feature',\n",
    "            'geometry': mapping(geom),\n",
    "            'properties': {\n",
    "                'id': location_id,\n",
    "                'location_name': name,\n",
    "                'population': pop\n",
    "            }\n",
    "        })\n",
    "        data[location_id] = { \n",
    "            'location_name': name,\n",
    "            'population': pop, \n",
    "            'values': {} \n",
    "        }\n",
    "        for metric in metrics:\n",
    "            data[location_id]['values'][metric] = {}\n",
    "            for level in levels:\n",
    "                data[location_id]['values'][metric][level] = {}   \n",
    "            \n",
    "    for _, row in df.sort_values(by='location_name').iterrows():\n",
    "        name = row['location_name']\n",
    "        date = row['date']\n",
    "        dates.add(date)\n",
    "        if not name in name_to_id:\n",
    "            location_id = next_location_id\n",
    "            name_to_id[name] = location_id\n",
    "            setup_location(name, location_id)\n",
    "            next_location_id += 1\n",
    "        else:\n",
    "            location_id = name_to_id[name]\n",
    "        for metric in metrics:\n",
    "            for level in levels:\n",
    "                v = row['{}_{}'.format(metric, level)]\n",
    "                if np.isnan(v):\n",
    "                    v = None\n",
    "                data[location_id]['values'][metric][level][date] = v\n",
    "    \n",
    "    return features, data, dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the features and data for all locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features, all_data, dates = gather_data_for_locations(ihme_df)\n",
    "\n",
    "# Set the dates into the config for visualization.\n",
    "ihme_config['dates'] = sorted(list(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define methods for generating breaks that will be used to color the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_values(data, per_capita_base=None):\n",
    "    result = {}\n",
    "    for m in metrics:\n",
    "        result[m] = {}\n",
    "        for l in levels:\n",
    "            result[m][l] = []\n",
    "\n",
    "    for location_id, location_data in data.items():\n",
    "        if per_capita_base is not None:\n",
    "            pop = location_data['population']\n",
    "            denom = pop / per_capita_base\n",
    "        else:\n",
    "            denom = 1\n",
    "                \n",
    "        for m in metrics:\n",
    "            for l in levels:\n",
    "                for v in location_data['values'][m][l].values():\n",
    "                    if v is not None:\n",
    "                        result[m][l].append(v / denom)\n",
    "                \n",
    "    return dict(result)\n",
    "\n",
    "def compute_breaks(data, per_capita_base=None):\n",
    "    result = {}\n",
    "    for m in metrics:\n",
    "        result[m] = {}\n",
    "        for l in levels:\n",
    "            result[m][l] = None\n",
    "            \n",
    "    prop_values = get_prop_values(data, per_capita_base)\n",
    "    for m in prop_values:\n",
    "        for l in prop_values[m]:\n",
    "            result[m][l] = jenks_breaks(prop_values[m][l], nb_class=6)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define methods for creating GeoJSON and breaks files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(location_names, agg_id):\n",
    "    features = [\n",
    "        f for f in all_features\n",
    "        if f['properties']['location_name'] in location_names\n",
    "    ]\n",
    "    \n",
    "    feature_collection = {\n",
    "        'type': 'FeatureCollection',\n",
    "        'features': features\n",
    "    }\n",
    "    \n",
    "    data = dict([\n",
    "        (k, v) for (k, v) in all_data.items()\n",
    "        if v['location_name'] in location_names\n",
    "    ])\n",
    "\n",
    "    # Set breaks\n",
    "    ihme_config['aggregations'][agg_id]['breaks']['totals'] = compute_breaks(data)\n",
    "    ihme_config['aggregations'][agg_id]['breaks']['per_capita'] = compute_breaks(\n",
    "        data, ihme_config['aggregations'][agg_id]['per_capita_base']\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        feature_collection,\n",
    "        data,\n",
    "        processed_data_path('ihme-{}.geojson'.format(agg_id)),\n",
    "        processed_data_path('ihme-{}-data.json'.format(agg_id))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Countries\n",
    "## Account for Georgia as a country name (not in IHME data...yet)\n",
    "country_names = list(country_geom_by_name.keys())\n",
    "country_names.remove('Georgia')\n",
    "\n",
    "(\n",
    "    country_feature_collection,\n",
    "    country_data,\n",
    "    country_geojson_path,\n",
    "    country_data_path\n",
    ") = create_data(country_names, 'country')\n",
    "\n",
    "# For Regions\n",
    "## Account for Mexico as a subnational region name\n",
    "region_names = list(region_geom_by_name.keys())\n",
    "region_names.remove('Mexico')\n",
    "(\n",
    "    region_feature_collection,\n",
    "    region_data,\n",
    "    region_geojson_path, \n",
    "    region_data_path\n",
    ") = create_data(region_names, 'region')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(country_geojson_path, 'w') as f:\n",
    "    f.write(json.dumps(country_feature_collection, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(country_data_path, 'w') as f:\n",
    "    f.write(json.dumps(country_data, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(region_geojson_path, 'w') as f:\n",
    "    f.write(json.dumps(region_feature_collection, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(region_data_path, 'w') as f:\n",
    "    f.write(json.dumps(region_data, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(processed_data_path('ihme-config.json'), 'w') as f:\n",
    "    f.write(json.dumps(ihme_config, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_config['aggregations']['country']['breaks']['per_capita']['deaths']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_config['aggregations']['region']['breaks']['per_capita']['deaths']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_config['aggregations']['region']['breaks']['totals']['deaths']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
